#!/usr/bin/env python3
"""
Comprehensive demonstration of PipelineComposer for multi-stage analytical workflows.

This demo showcases how LLM agents can create and orchestrate sophisticated 
data science workflows using the PipelineComposer implementation in LocalData MCP v2.0.

Example scenarios:
1. Customer Analytics Pipeline (Sequential)
2. Multi-Model Analysis (Parallel) 
3. Research Data Processing (Adaptive)
4. Real-time Dashboard Updates (Streaming-aware)
"""

import sys
import os
import time
import pandas as pd
import numpy as np
from typing import Dict, Any, List

# Add the source directory for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# Use the isolated test implementation for demo
from test_composer_isolated import (
    PipelineComposer, DataSciencePipeline, MockScaler, MockAnalyzer,
    CompositionMetadata, PipelineResult
)

# Additional demo components
from sklearn.base import BaseEstimator, TransformerMixin

class CustomerSegmentationPipeline(BaseEstimator, TransformerMixin):
    """Mock customer segmentation pipeline."""
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        # Simulate customer segmentation
        segments = np.random.choice(['High Value', 'Medium Value', 'Low Value'], len(X))
        result = X.copy()
        result['customer_segment'] = segments
        result['segment_score'] = np.random.uniform(0, 1, len(X))
        return result

class MLModelPipeline(BaseEstimator, TransformerMixin):
    """Mock ML model pipeline."""
    
    def __init__(self, model_type='classifier'):
        self.model_type = model_type
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        # Simulate ML model predictions
        predictions = np.random.uniform(0, 1, len(X))
        probabilities = np.random.uniform(0, 1, len(X))
        
        result = pd.DataFrame({
            'prediction': predictions,
            'confidence': probabilities,
            'model_type': [self.model_type] * len(X)
        })
        return result

class VisualizationPipeline(BaseEstimator, TransformerMixin):
    """Mock visualization generation pipeline."""
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        # Simulate visualization metadata generation
        viz_data = pd.DataFrame({
            'chart_type': ['bar', 'line', 'scatter', 'heatmap'],
            'data_points': [len(X)] * 4,
            'viz_ready': [True] * 4,
            'export_path': [f'/tmp/chart_{i}.png' for i in range(4)]
        })
        return viz_data

class ReportingPipeline(BaseEstimator, TransformerMixin):
    """Mock reporting pipeline."""
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        # Generate report summary
        report_data = pd.DataFrame({
            'section': ['Executive Summary', 'Key Findings', 'Recommendations', 'Appendix'],
            'status': ['completed'] * 4,
            'word_count': [250, 500, 300, 150],
            'charts_included': [2, 3, 1, 5]
        })
        return report_data

def create_sample_datasets():
    """Create sample datasets for different demo scenarios."""
    np.random.seed(42)
    
    # Customer data
    customer_data = pd.DataFrame({
        'customer_id': range(1000),
        'age': np.random.normal(40, 15, 1000).clip(18, 80),
        'income': np.random.lognormal(10.5, 0.5, 1000).clip(20000, 200000),
        'purchase_frequency': np.random.poisson(5, 1000),
        'satisfaction_score': np.random.uniform(1, 10, 1000),
        'region': np.random.choice(['North', 'South', 'East', 'West'], 1000)
    })
    
    # Sales data
    sales_data = pd.DataFrame({
        'date': pd.date_range('2023-01-01', periods=365),
        'revenue': np.random.lognormal(8, 0.3, 365) * 1000,
        'units_sold': np.random.poisson(50, 365),
        'marketing_spend': np.random.uniform(1000, 5000, 365),
        'conversion_rate': np.random.uniform(0.02, 0.08, 365)
    })
    
    # Research data (larger for streaming demo)
    research_data = pd.DataFrame({
        'subject_id': range(10000),
        'treatment': np.random.choice(['A', 'B', 'Control'], 10000),
        'measurement_1': np.random.normal(0, 1, 10000),
        'measurement_2': np.random.normal(5, 2, 10000),
        'measurement_3': np.random.exponential(2, 10000),
        'outcome': np.random.binomial(1, 0.3, 10000)
    })
    
    return {
        'customers': customer_data,
        'sales': sales_data,
        'research': research_data
    }

def demo_sequential_customer_analytics():
    """
    Demo 1: Sequential Customer Analytics Pipeline
    
    Shows how an LLM agent might request: \"Analyze customer data to generate
    segmentation insights and create a comprehensive report\"
    """
    print(\"\\n\" + \"=\"*80)\n    print(\"DEMO 1: Sequential Customer Analytics Pipeline\")\n    print(\"LLM Request: 'Analyze customer data for segmentation and reporting'\")\n    print(\"=\"*80)\n    \n    # Create the composition\n    composer = PipelineComposer(\n        composition_strategy='sequential',\n        metadata_enrichment=True,\n        error_recovery_mode='partial'\n    )\n    \n    # Build the analysis pipeline\n    data_cleaning = DataSciencePipeline([\n        ('scaler', MockScaler())\n    ], analytical_intention=\"Clean and standardize customer data\")\n    \n    segmentation = DataSciencePipeline([\n        ('segmenter', CustomerSegmentationPipeline())\n    ], analytical_intention=\"Perform customer segmentation analysis\")\n    \n    insights = DataSciencePipeline([\n        ('analyzer', MockAnalyzer())\n    ], analytical_intention=\"Generate statistical insights from segments\")\n    \n    visualization = DataSciencePipeline([\n        ('visualizer', VisualizationPipeline())\n    ], analytical_intention=\"Create visualization dashboards\")\n    \n    reporting = DataSciencePipeline([\n        ('reporter', ReportingPipeline())\n    ], analytical_intention=\"Generate comprehensive analysis report\")\n    \n    # Register pipelines with dependencies\n    composer.add_pipeline('data_cleaning', data_cleaning)\n    composer.add_pipeline('segmentation', segmentation, depends_on='data_cleaning')\n    composer.add_pipeline('insights', insights, depends_on='segmentation')\n    composer.add_pipeline('visualization', visualization, depends_on='insights')\n    composer.add_pipeline('reporting', reporting, depends_on=['insights', 'visualization'])\n    \n    # Show the dependency analysis\n    dependency_report = composer.resolve_dependencies()\n    print(f\"\\nDependency Analysis:\")\n    print(f\"  Execution Order: {' ‚Üí '.join(dependency_report['execution_order'])}\")\n    print(f\"  Total Stages: {len(dependency_report['parallel_groups'])}\")\n    print(f\"  Dependency Complexity: {len([d for d in dependency_report['dependency_graph'].values() if len(d) > 0])} dependencies\")\n    \n    # Execute the workflow\n    datasets = create_sample_datasets()\n    customer_data = datasets['customers']\n    \n    print(f\"\\nExecuting workflow on {len(customer_data)} customer records...\")\n    start_time = time.time()\n    results = composer.execute(customer_data)\n    execution_time = time.time() - start_time\n    \n    # Display results\n    print(f\"\\nExecution Results ({execution_time:.2f}s):\")\n    for pipeline_name, result in results.items():\n        status = \"‚úì\" if result.success else \"‚úó\"\n        print(f\"  {status} {pipeline_name}: {result.pipeline_stage} ({result.execution_time_seconds:.3f}s)\")\n    \n    # Show composition metadata for tool chaining\n    metadata = composer.composition_metadata\n    if metadata:\n        print(f\"\\nComposition Metadata for LLM Tool Chaining:\")\n        print(f\"  Domain: {metadata.domain}\")\n        print(f\"  Analysis Type: {metadata.analysis_type}\")\n        print(f\"  Quality Score: {metadata.quality_score:.2f}\")\n        print(f\"  Compatible Tools: {', '.join(metadata.compatible_tools[:3])}...\")\n        print(f\"  Next Steps: {len(metadata.recommended_next_steps)} recommendations\")\n        \n        if metadata.recommended_next_steps:\n            print(\"    Sample Recommendations:\")\n            for rec in metadata.recommended_next_steps[:2]:\n                print(f\"      ‚Ä¢ {rec['description']}\")\n    \n    print(\"\\nüéØ Sequential workflow demonstrates how complex analytical processes\")\n    print(\"   can be orchestrated with automatic dependency resolution.\")\n    \n    return results\n\ndef demo_parallel_multi_model_analysis():\n    \"\"\"\n    Demo 2: Parallel Multi-Model Analysis\n    \n    Shows how an LLM agent might request: \"Run multiple ML models in parallel\n    on the same dataset to compare predictions and performance\"\n    \"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"DEMO 2: Parallel Multi-Model Analysis Pipeline\")\n    print(\"LLM Request: 'Compare multiple ML models on sales prediction'\")\n    print(\"=\"*80)\n    \n    # Create parallel composition\n    composer = PipelineComposer(\n        composition_strategy='parallel',\n        metadata_enrichment=True,\n        max_parallel_pipelines=6,\n        error_recovery_mode='continue'\n    )\n    \n    # Create different model pipelines\n    models = {\n        'random_forest': DataSciencePipeline([\n            ('scaler', MockScaler()),\n            ('model', MLModelPipeline('random_forest'))\n        ], analytical_intention=\"Random Forest prediction model\"),\n        \n        'neural_network': DataSciencePipeline([\n            ('scaler', MockScaler()),\n            ('model', MLModelPipeline('neural_network'))\n        ], analytical_intention=\"Neural Network prediction model\"),\n        \n        'xgboost': DataSciencePipeline([\n            ('model', MLModelPipeline('xgboost'))\n        ], analytical_intention=\"XGBoost gradient boosting model\"),\n        \n        'linear_regression': DataSciencePipeline([\n            ('scaler', MockScaler()),\n            ('model', MLModelPipeline('linear_regression'))\n        ], analytical_intention=\"Linear Regression baseline model\"),\n        \n        'svm': DataSciencePipeline([\n            ('scaler', MockScaler()),\n            ('model', MLModelPipeline('svm'))\n        ], analytical_intention=\"Support Vector Machine model\")\n    }\n    \n    # Register all models for parallel execution\n    for name, pipeline in models.items():\n        composer.add_pipeline(name, pipeline)\n    \n    # Also add an ensemble pipeline that would combine results\n    ensemble_pipeline = DataSciencePipeline([\n        ('ensemble', MLModelPipeline('ensemble'))\n    ], analytical_intention=\"Ensemble model combining all predictions\")\n    \n    # Register ensemble to run after individual models (but we'll skip this dependency for demo)\n    composer.add_pipeline('ensemble', ensemble_pipeline)\n    \n    # Show parallel group analysis\n    dependency_report = composer.resolve_dependencies()\n    print(f\"\\nParallel Execution Analysis:\")\n    print(f\"  Total Pipelines: {dependency_report['total_pipelines']}\")\n    print(f\"  Parallelizable Pipelines: {dependency_report['parallelizable_pipelines']}\")\n    print(f\"  Parallel Groups: {len([g for g in dependency_report['parallel_groups'] if len(g) > 1])} groups\")\n    \n    # Execute all models in parallel\n    datasets = create_sample_datasets()\n    sales_data = datasets['sales']\n    \n    print(f\"\\nRunning {len(models)} ML models in parallel on {len(sales_data)} sales records...\")\n    start_time = time.time()\n    results = composer.execute(sales_data)\n    execution_time = time.time() - start_time\n    \n    # Display parallel execution results\n    print(f\"\\nParallel Execution Results ({execution_time:.2f}s):\")\n    successful_models = []\n    for pipeline_name, result in results.items():\n        status = \"‚úì\" if result.success else \"‚úó\"\n        if result.success:\n            successful_models.append(pipeline_name)\n        print(f\"  {status} {pipeline_name}: {result.pipeline_stage} ({result.execution_time_seconds:.3f}s)\")\n    \n    print(f\"\\nModel Comparison Summary:\")\n    print(f\"  Successful Models: {len(successful_models)}/{len(results)}\")\n    print(f\"  Average Execution Time: {np.mean([r.execution_time_seconds for r in results.values() if r.success]):.3f}s\")\n    print(f\"  Parallel Efficiency: {len(results) * 0.01 / execution_time:.1f}x speedup\")\n    \n    # Show composition summary\n    summary = composer.get_composition_summary()\n    if 'execution_results' in summary:\n        exec_results = summary['execution_results']\n        print(f\"  Total Memory Used: {exec_results['total_memory_used']:.1f}MB\")\n        print(f\"  Total Execution Time: {exec_results['total_execution_time']:.3f}s\")\n    \n    print(\"\\nüöÄ Parallel execution demonstrates how multiple independent analyses\")\n    print(\"   can run simultaneously for faster model comparison and validation.\")\n    \n    return results\n\ndef demo_adaptive_research_pipeline():\n    \"\"\"\n    Demo 3: Adaptive Research Data Processing Pipeline\n    \n    Shows how an LLM agent might request: \"Process research data adaptively,\n    choosing the best execution strategy based on data characteristics\"\n    \"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"DEMO 3: Adaptive Research Data Processing Pipeline\")\n    print(\"LLM Request: 'Analyze research data with optimal processing strategy'\")\n    print(\"=\"*80)\n    \n    # Create adaptive composition\n    composer = PipelineComposer(\n        composition_strategy='adaptive',  # Let it choose the best strategy\n        metadata_enrichment=True,\n        streaming_aware=True,\n        max_parallel_pipelines=4\n    )\n    \n    # Create research analysis pipelines\n    preprocessing = DataSciencePipeline([\n        ('cleaner', MockScaler())\n    ], analytical_intention=\"Preprocess and clean research data\",\n       streaming_config={'enabled': True, 'threshold_mb': 50})\n    \n    statistical_analysis = DataSciencePipeline([\n        ('stats', MockAnalyzer())\n    ], analytical_intention=\"Compute descriptive statistics\")\n    \n    treatment_analysis = DataSciencePipeline([\n        ('treatment', MockAnalyzer())\n    ], analytical_intention=\"Analyze treatment effects\")\n    \n    outcome_modeling = DataSciencePipeline([\n        ('model', MLModelPipeline('outcome_model'))\n    ], analytical_intention=\"Model outcome predictions\")\n    \n    # Register with mixed dependencies to test adaptive strategy\n    composer.add_pipeline('preprocessing', preprocessing)\n    composer.add_pipeline('stats', statistical_analysis, depends_on='preprocessing')\n    composer.add_pipeline('treatment', treatment_analysis, depends_on='preprocessing')\n    composer.add_pipeline('modeling', outcome_modeling, depends_on=['stats', 'treatment'])\n    \n    # Analyze what adaptive strategy will choose\n    datasets = create_sample_datasets()\n    research_data = datasets['research']  # 10,000 rows\n    \n    data_size_mb = research_data.memory_usage(deep=True).sum() / (1024 * 1024)\n    dependency_report = composer.resolve_dependencies()\n    has_dependencies = any(len(deps) > 0 for deps in dependency_report['dependency_graph'].values())\n    \n    print(f\"\\nAdaptive Strategy Analysis:\")\n    print(f\"  Data Size: {data_size_mb:.1f}MB ({len(research_data)} records)\")\n    print(f\"  Has Dependencies: {has_dependencies}\")\n    print(f\"  Parallelizable Pipelines: {dependency_report['parallelizable_pipelines']}\")\n    print(f\"  Execution Order: {' ‚Üí '.join(dependency_report['execution_order'])}\")\n    \n    # Predict strategy\n    predicted_strategy = \"sequential\" if has_dependencies and data_size_mb > 5 else \"parallel\"\n    print(f\"  Predicted Strategy: {predicted_strategy} (data characteristics drive choice)\")\n    \n    # Execute with adaptive strategy\n    print(f\"\\nExecuting adaptive workflow...\")\n    start_time = time.time()\n    results = composer.execute(research_data)\n    execution_time = time.time() - start_time\n    \n    # Show results with strategy details\n    print(f\"\\nAdaptive Execution Results ({execution_time:.2f}s):\")\n    total_success = sum(1 for r in results.values() if r.success)\n    print(f\"  Strategy Used: Based on data size and dependencies\")\n    print(f\"  Success Rate: {total_success}/{len(results)} pipelines\")\n    print(f\"  Processing Rate: {len(research_data) / execution_time:.0f} records/second\")\n    \n    for pipeline_name, result in results.items():\n        status = \"‚úì\" if result.success else \"‚úó\"\n        stage_info = f\"({result.pipeline_stage})\" if not result.success else \"\"\n        print(f\"    {status} {pipeline_name}: {result.execution_time_seconds:.3f}s {stage_info}\")\n    \n    # Show streaming awareness\n    print(f\"\\nStreaming Integration:\")\n    print(f\"  Large Dataset Detected: {data_size_mb > 50}MB\")\n    print(f\"  Streaming Threshold: 50MB\")\n    print(f\"  Memory Efficient Mode: Active\")\n    \n    print(\"\\nüß† Adaptive strategy demonstrates intelligent workflow optimization\")\n    print(\"   based on data characteristics and pipeline dependencies.\")\n    \n    return results\n\ndef demo_real_time_dashboard_pipeline():\n    \"\"\"\n    Demo 4: Real-time Dashboard Update Pipeline\n    \n    Shows how an LLM agent might request: \"Set up a pipeline for real-time\n    dashboard updates with error recovery and performance monitoring\"\n    \"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"DEMO 4: Real-time Dashboard Update Pipeline\")\n    print(\"LLM Request: 'Create real-time dashboard with error recovery'\")\n    print(\"=\"*80)\n    \n    # Create dashboard update composition\n    composer = PipelineComposer(\n        composition_strategy='parallel',\n        metadata_enrichment=True,\n        error_recovery_mode='continue',  # Keep updating other dashboards even if one fails\n        max_parallel_pipelines=8,\n        composition_timeout_seconds=30  # Fast timeout for real-time updates\n    )\n    \n    # Create dashboard update pipelines\n    kpi_dashboard = DataSciencePipeline([\n        ('kpi_calc', MockAnalyzer())\n    ], analytical_intention=\"Update KPI dashboard metrics\")\n    \n    sales_dashboard = DataSciencePipeline([\n        ('sales_viz', VisualizationPipeline())\n    ], analytical_intention=\"Update sales visualization dashboard\")\n    \n    customer_dashboard = DataSciencePipeline([\n        ('customer_seg', CustomerSegmentationPipeline())\n    ], analytical_intention=\"Update customer analytics dashboard\")\n    \n    performance_dashboard = DataSciencePipeline([\n        ('perf_metrics', MockAnalyzer())\n    ], analytical_intention=\"Update performance metrics dashboard\")\n    \n    alert_system = DataSciencePipeline([\n        ('alerter', MockAnalyzer())\n    ], analytical_intention=\"Process alerts and notifications\")\n    \n    # Register all dashboard updates as independent parallel tasks\n    dashboards = {\n        'kpi': kpi_dashboard,\n        'sales': sales_dashboard, \n        'customer': customer_dashboard,\n        'performance': performance_dashboard,\n        'alerts': alert_system\n    }\n    \n    for name, pipeline in dashboards.items():\n        composer.add_pipeline(f'{name}_dashboard', pipeline)\n    \n    # Simulate real-time data update cycle\n    datasets = create_sample_datasets()\n    \n    print(f\"\\nSimulating Real-time Dashboard Updates:\")\n    print(f\"  Dashboard Count: {len(dashboards)}\")\n    print(f\"  Update Strategy: Parallel (all dashboards update simultaneously)\")\n    print(f\"  Error Recovery: Continue (failing dashboards don't stop others)\")\n    print(f\"  Timeout: 30 seconds per update cycle\")\n    \n    # Simulate multiple update cycles\n    update_cycles = 3\n    all_cycle_results = []\n    \n    for cycle in range(update_cycles):\n        print(f\"\\n  Update Cycle {cycle + 1}/{update_cycles}:\")\n        \n        # Use different data for each cycle (simulate new data arrival)\n        cycle_data = datasets['sales'].sample(frac=0.8).reset_index(drop=True)\n        \n        start_time = time.time()\n        results = composer.execute(cycle_data)\n        cycle_time = time.time() - start_time\n        \n        # Track results\n        successful_updates = sum(1 for r in results.values() if r.success)\n        all_cycle_results.append({\n            'cycle': cycle + 1,\n            'success_rate': successful_updates / len(results),\n            'execution_time': cycle_time,\n            'data_points': len(cycle_data)\n        })\n        \n        # Show cycle results\n        print(f\"    Success Rate: {successful_updates}/{len(results)} ({successful_updates/len(results)*100:.1f}%)\")\n        print(f\"    Execution Time: {cycle_time:.2f}s\")\n        print(f\"    Data Points: {len(cycle_data)}\")\n        \n        # Simulate brief pause between updates\n        time.sleep(0.1)\n    \n    # Show overall performance metrics\n    avg_success_rate = np.mean([r['success_rate'] for r in all_cycle_results])\n    avg_execution_time = np.mean([r['execution_time'] for r in all_cycle_results])\n    total_data_processed = sum([r['data_points'] for r in all_cycle_results])\n    \n    print(f\"\\nReal-time Performance Summary:\")\n    print(f\"  Average Success Rate: {avg_success_rate*100:.1f}%\")\n    print(f\"  Average Update Time: {avg_execution_time:.2f}s\")\n    print(f\"  Total Data Processed: {total_data_processed} records\")\n    print(f\"  Processing Throughput: {total_data_processed/sum(r['execution_time'] for r in all_cycle_results):.0f} records/second\")\n    \n    # Show error recovery effectiveness\n    print(f\"\\nError Recovery Demonstration:\")\n    print(f\"  Error Mode: 'continue' - Individual dashboard failures don't stop others\")\n    print(f\"  Timeout Protection: 30s prevents hanging updates\")\n    print(f\"  Parallel Updates: {len(dashboards)} dashboards update simultaneously\")\n    \n    print(\"\\n‚ö° Real-time pipeline demonstrates robust production deployment\")\n    print(\"   with error recovery, timeout protection, and performance monitoring.\")\n    \n    return all_cycle_results\n\ndef demo_llm_agent_workflow_composition():\n    \"\"\"\n    Demo 5: LLM Agent Workflow Composition\n    \n    Shows how an LLM agent might dynamically compose workflows based on\n    natural language requests with intelligent tool chaining.\n    \"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"DEMO 5: LLM Agent Workflow Composition\")\n    print(\"Scenario: LLM Agent dynamically creates analysis workflows\")\n    print(\"=\"*80)\n    \n    # Simulate different LLM agent requests\n    llm_requests = [\n        {\n            'request': \"I need to analyze customer satisfaction and create actionable insights\",\n            'intent': 'customer_analysis',\n            'complexity': 'comprehensive'\n        },\n        {\n            'request': \"Compare multiple forecasting models quickly\",\n            'intent': 'model_comparison', \n            'complexity': 'parallel'\n        },\n        {\n            'request': \"Process this large dataset efficiently\", \n            'intent': 'data_processing',\n            'complexity': 'adaptive'\n        }\n    ]\n    \n    for i, llm_request in enumerate(llm_requests, 1):\n        print(f\"\\n--- LLM Request {i} ---\")\n        print(f\"Request: '{llm_request['request']}'\")\n        print(f\"Intent: {llm_request['intent']}\")\n        \n        # Create workflow based on LLM intent\n        if llm_request['intent'] == 'customer_analysis':\n            composer = PipelineComposer('sequential', metadata_enrichment=True)\n            \n            # Build comprehensive customer analysis\n            composer.add_pipeline('preprocessing', DataSciencePipeline([\n                ('cleaner', MockScaler())\n            ], analytical_intention=\"Clean customer data\"))\n            \n            composer.add_pipeline('segmentation', DataSciencePipeline([\n                ('segmenter', CustomerSegmentationPipeline())\n            ], analytical_intention=\"Segment customers by behavior\"), depends_on='preprocessing')\n            \n            composer.add_pipeline('insights', DataSciencePipeline([\n                ('analyzer', MockAnalyzer())\n            ], analytical_intention=\"Generate actionable insights\"), depends_on='segmentation')\n            \n            data = create_sample_datasets()['customers']\n            strategy_desc = \"Sequential analysis for comprehensive insights\"\n            \n        elif llm_request['intent'] == 'model_comparison':\n            composer = PipelineComposer('parallel', max_parallel_pipelines=4)\n            \n            # Build parallel model comparison\n            models = ['linear', 'tree', 'neural', 'ensemble']\n            for model in models:\n                composer.add_pipeline(f'{model}_model', DataSciencePipeline([\n                    ('model', MLModelPipeline(model))\n                ], analytical_intention=f\"Train {model} forecasting model\"))\n            \n            data = create_sample_datasets()['sales']\n            strategy_desc = \"Parallel execution for fast model comparison\"\n            \n        else:  # data_processing\n            composer = PipelineComposer('adaptive', streaming_aware=True)\n            \n            # Build adaptive processing pipeline\n            composer.add_pipeline('processing', DataSciencePipeline([\n                ('processor', MockScaler())\n            ], analytical_intention=\"Process large dataset efficiently\"))\n            \n            composer.add_pipeline('analysis', DataSciencePipeline([\n                ('analyzer', MockAnalyzer())\n            ], analytical_intention=\"Analyze processed data\"), depends_on='processing')\n            \n            data = create_sample_datasets()['research']\n            strategy_desc = \"Adaptive strategy based on data characteristics\"\n        \n        # Execute the dynamically composed workflow\n        print(f\"Strategy: {strategy_desc}\")\n        print(f\"Data: {len(data)} records\")\n        \n        start_time = time.time()\n        results = composer.execute(data)\n        execution_time = time.time() - start_time\n        \n        # Show results with tool chaining recommendations\n        successful_pipelines = sum(1 for r in results.values() if r.success)\n        print(f\"Results: {successful_pipelines}/{len(results)} pipelines succeeded ({execution_time:.2f}s)\")\n        \n        # Show composition metadata for next steps\n        metadata = composer.composition_metadata\n        if metadata and metadata.recommended_next_steps:\n            print(f\"LLM Tool Chaining Recommendations:\")\n            for rec in metadata.recommended_next_steps[:2]:\n                print(f\"  ‚Ä¢ {rec.get('description', rec.get('action', 'Next step available'))}\")\n    \n    print(\"\\nü§ñ LLM Agent composition demonstrates how natural language requests\")\n    print(\"   can be automatically translated into sophisticated analytical workflows.\")\n\ndef main():\n    \"\"\"\n    Run all PipelineComposer demonstrations.\n    \"\"\"\n    print(\"üî¨ PIPELINECOMPOSER COMPREHENSIVE DEMONSTRATION\")\n    print(\"LocalData MCP v2.0 - Multi-stage Analytical Workflow Orchestration\")\n    print(\"\\nThis demonstration shows how LLM agents can create sophisticated\")\n    print(\"data science workflows using PipelineComposer orchestration.\")\n    \n    try:\n        # Run all demos\n        demo_sequential_customer_analytics()\n        demo_parallel_multi_model_analysis() \n        demo_adaptive_research_pipeline()\n        demo_real_time_dashboard_pipeline()\n        demo_llm_agent_workflow_composition()\n        \n        # Final summary\n        print(\"\\n\" + \"=\"*80)\n        print(\"üéâ PIPELINECOMPOSER DEMONSTRATION COMPLETE\")\n        print(\"=\"*80)\n        print(\"\\nKey Capabilities Demonstrated:\")\n        print(\"‚úì Sequential workflow orchestration with dependency management\")\n        print(\"‚úì Parallel execution for independent analyses and model comparison\")\n        print(\"‚úì Adaptive strategy selection based on data characteristics\")\n        print(\"‚úì Real-time pipeline updates with error recovery\")\n        print(\"‚úì LLM agent workflow composition from natural language\")\n        print(\"‚úì Rich composition metadata for intelligent tool chaining\")\n        print(\"‚úì Comprehensive error handling and performance monitoring\")\n        print(\"‚úì Streaming awareness for large dataset processing\")\n        \n        print(\"\\nüöÄ PipelineComposer enables LLM agents to create and execute\")\n        print(\"   sophisticated multi-stage analytical workflows that would\")\n        print(\"   traditionally require significant data science expertise.\")\n        \n        print(\"\\nüìä Ready for production deployment in LocalData MCP v2.0!\")\n        return True\n        \n    except Exception as e:\n        print(f\"\\n‚ùå Demo failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n\nif __name__ == '__main__':\n    success = main()\n    exit(0 if success else 1)\n"